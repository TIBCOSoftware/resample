<!-- Copyright 2021. TIBCO Software Inc. -->
<!-- This file is subject to the license terms contained -->
<!-- in the license file that is distributed with this file. -->

<!doctype s-function-doc system "s-function-doc.dtd" [
<!entity % S-OLD "INCLUDE">
]
>
<s-function-doc>
<s-topics>
   <s-topic>t.test</s-topic>
   <s-topic>saddlepoint.test</s-topic>
</s-topics>
<s-title>
Student's t-Tests 
</s-title>
<s-description>
Performs a one-sample, two-sample, or paired t-test, 
and a saddlepoint variation. 
</s-description>
<s-usage>
<s-old-style-usage>
t.test(x, y=NULL, alternative="two.sided", mu=0, paired=F, 
       var.equal=F, conf.level=.95, treatment) 
saddlepoint.test(x, y=NULL, alternative="two.sided", mu=0, paired=F, 
       var.equal=F, conf.level=.95, treatment) 
</s-old-style-usage>
</s-usage>
<s-args-required>
<s-arg name="x">
numeric vector. <code>NA</code>s and <code>Inf</code>s are allowed but 
will be removed. 
</s-arg>
</s-args-required>
<s-args-optional>
<s-arg name="y">
numeric vector. <code>NA</code>s and <code>Inf</code>s are allowed but will be 
removed. If <code>paired=TRUE</code>, 
then <code>x</code> and <code>y</code> must have the same length, and observation 
pairs <code>(x[i], y[i])</code> with at least one <code>NA</code> or <code>Inf</code> will be 
removed. 
</s-arg>
<s-arg name="alternative">
character string, one of <code>"greater"</code>, <code>"less"</code> or <code>"two.sided"</code>, or just the 
initial letter of each, indicating 
the specification of the alternative hypothesis. For the 
one-sample and paired t-tests, <code>alternative</code> refers to the true 
mean of the parent population in relation to the hypothesized value <code>mu</code>. 
For two-sample t-tests, <code>alternative</code> refers 
to the difference between the true population mean for <code>x</code> and that for <code>y</code>, 
in relation to <code>mu</code>. 
</s-arg>
<s-arg name="mu">
a single number representing the value of the mean or 
difference in means specified by the null hypothesis. 
</s-arg>
<s-arg name="paired">
logical flag: if <code>TRUE</code>, <code>x</code> and <code>y</code> are considered as paired vectors. 
</s-arg>
<s-arg name="var.equal">
logical flag: if <code>TRUE</code>, the variances of the parent populations of <code>x</code> 
and <code>y</code> are assumed equal. Argument <code>var.equal</code> should be supplied 
only for the two-sample (i.e., unpaired) tests. 
</s-arg>
<s-arg name="conf.level">
confidence level for the returned confidence interval, restricted to lie between zero and one. 
</s-arg>
<s-arg name="treatment">
a vector the same length as <code>x</code>, with two unique values.  This is  
a grouping variable used to split <code>x</code> into two samples.  If supplied 
then <code>y</code> should not be used. 
</s-arg>
</s-args-optional>
<s-value>
A list of class <code>"htest")</code> (for <code>t.test</code>) or 
<code>c("htest.saddlepoint", "htest")</code> (for <code>saddlepoint.test</code>), 
containing the following components: 
<s-return-component name="statistic">
the t-statistic, with <code>names</code> attribute <code>"t"</code>. 
</s-return-component>
<s-return-component name="parameters">
the degrees of freedom of the t-distribution associated  
with <code>statistic</code>. Component <code>parameters</code> has <code>names</code> attribute <code>"df"</code>. 
</s-return-component>
<s-return-component name="p.value">
the p-value for the test. 
</s-return-component>
<s-return-component name="conf.int">
a confidence interval (vector of length 2) for the true mean or difference in 
means. The confidence level is recorded in the attribute <code>conf.level</code>. 
When <code>alternative</code> is not <code>"two.sided"</code>, the confidence interval  
will be half-infinite, to reflect the interpretation of a confidence 
interval as the set of all values <code>k</code> for which one would not reject the 
null hypothesis that the true mean or difference in means is <code>k</code>. 
Here infinity will be represented by <code>NA</code>. 
</s-return-component>
<s-return-component name="estimate">
vector of length 1 or 2, giving 
the sample mean(s) or mean of differences; these estimate the corresponding 
population parameters. Component <code>estimate</code> has a <code>names</code>  
attribute describing its elements. 
</s-return-component>
<s-return-component name="null.value">
the value of the mean or difference in means 
specified by the null hypothesis. This equals the input  
argument <code>mu</code>. Component <code>null.value</code> has a <code>names</code>  
attribute describing its elements. 
</s-return-component>
<s-return-component name="alternative">
records the value of the input argument <code>alternative</code>: <code>"greater"</code>, <code>"less"</code>  
or <code>"two.sided"</code>. 
</s-return-component>
<s-return-component name="method">
character string giving the name of the test used. 
</s-return-component>
<s-return-component name="data.name">
a character string (vector of length 1) containing the actual names of the input  
vectors <code>x</code> and <code>y</code>. 
<p>
In addition, in one-sample or paired applications, 
<code>saddlepoint.test</code> adds a 
<code>"saddlepoint"</code> attribute containing 
a saddlepoint approximation to bootstrap tilting 
confidence intervals.  The attribute has components: 
</s-return-component>
<s-return-component name="method">
character string giving the name of the test used. 
</s-return-component>
<s-return-component name="p.value">
the p-value for the test. 
</s-return-component>
<s-return-component name="conf.int">
a confidence interval. 
</s-return-component>
<s-return-component name="tau0">
tilting parameter used in obtaining the p-value. 
</s-return-component>
<s-return-component name="tau.ci">
tilting parameter(s) used in obtaining the confidence interval. 
</s-return-component>
</s-value>

<s-section name="NULL HYPOTHESIS">
For the one-sample t-test, the null hypothesis 
is that the mean of the population from which <code>x</code> is drawn is <code>mu</code>. 
For the paired t-test, the null hypothesis is that the 
population mean of the difference <code>x - y</code> is equal to <code>mu</code>.  For 
the two-sample t-tests, 
the null hypothesis is that the population mean for <code>x</code> minus that 
for <code>y</code> is <code>mu</code>. 
<p>
The alternative hypothesis in each case 
indicates the direction of divergence of the population mean for <code>x</code> (or 
difference of means for <code>x</code> and <code>y</code>) 
from <code>mu</code> (i.e., <code>"greater"</code>, <code>"less"</code>, <code>"two.sided"</code>). 
</s-section>
<s-section name="TEST ASSUMPTIONS">

A t-statistic has a t distribution if the underlying populations are normal, 
the variances are equal, and you set <code>var.equal=TRUE</code>.   
These conditions are never satisfied in practice.   
More importantly, the actual distribution 
is approximately a t distribution if the sample sizes are reasonably 
large, the distributions are not skewed, and you set 
<code>var.equal=FALSE</code>.   
<p>
You should set <code>var.equal=TRUE</code> 
only if you have good reason to believe the variances are equal. 
We recommend that you not perform a hypothesis tests for equal 
variances -- while t-tests are robust against non-normality, 
variance tests are not; 
"To make a preliminary test on variances is rather like putting to sea in 
a rowing boat to find out whether conditions are sufficiently 
calm for a ocean linear to leave port!" (Box page 333). 
<p>
The effect of skewness cancels out in a two-sample problem with 
equal sample sizes where the underlying populations have the same 
variance and skewness.  In one-sample problems, or when sample sizes 
differ, the effect of skewness on the distribution of the t-statistic 
disappears very slowly as the sample size increases, 
at the rate O(1/sqrt(n)). 
<p>
The t-test and the associated confidence interval are quite robust with 
respect to level toward heavy-tailed non-Gaussian distributions 
(e.g., data with outliers). 
However, the t-test is quite non-robust with respect to power, 
and the confidence interval is quite non-robust with respect to average length, 
toward these same types of distributions. 
<p>
The usual t-test results are not very robust against skewed distributions 
(except in large samples).  If the distribution is skewed, these 
procedures have errors of order O(1/sqrt(n)). 
The bootstrap tilting intervals do not 
assume symmetry, 
and have errors of order O(1/n). 
<p>
The saddlepoint intervals are a topic of current research. 
</s-section>
<s-details>
<!-- <special target="troff">
.Tr
delim $$ 
.En
</special> 
 -->
(a) One-Sample t-Test. 
<p>
The arguments <code>y</code>, <code>paired</code> and <code>var.equal</code> determine the type of 
test.  If <code>y</code> is <code>NULL</code>, a one-sample t-test is carried out 
with <code>x</code>. Here <code>statistic</code> is given by: 
<!-- <special target="troff">
.Tr
<p>
t ~=~ { x bar ^-^ roman "mu" } over {{s sub x} / sqrt {n sub x}} 
<p>
where $x bar$, $s sub x$ and $n sub x$ are the sample mean, sample standard deviation
and sample size of `x' respectively.
If `x' was drawn from a normal population, $t$ has a t-distribution
with ${n sub x} ^-^ 1$ degrees of freedom under the null
hypothesis.
.En
</special> 
 -->
<!--Alternate nroff text-->
<br>
<code>t = (mean(x) - mu) / ( sqrt(var(x)) / sqrt(length(x)) )</code> 
<br>
If <code>x</code> was drawn from a normal population, <code>t</code> has a t-distribution 
with <code>length(x) - 1</code> degrees of freedom under the null 
hypothesis. 
<!--End alternate nroff text-->
<p>
(b) Paired t-Test. 
<p>
If <code>y</code> is not <code>NULL</code> and <code>paired=TRUE</code>, a paired t-test is performed; here <code>statistic</code> is 
defined through 
<!-- <special target="troff">
.Tr
<p>
t ~=~ { d bar ^-^ roman "mu" } over {{s sub d} / sqrt {n sub d}} 
<p>
where $d bar$, $s sub d$ and $n sub d$ are the sample mean, sample standard deviation and
sample size of the vector of differences `d = x - y'.
Under the null
hypothesis, $t$ follows a t-distribution with ${n sub d} ^-^ 1$ degrees of freedom, assuming
normality of the differences `d'.
.En
</special> 
 -->
<!--Alternate nroff text-->
<br>
<code>t = (mean(d) - mu) / ( sqrt(var(d)) / sqrt(length(d)) )</code> 
<br>
where <code>d</code> is the vector of differences <code>x - y</code>. 
Under the null 
hypothesis, <code>t</code> follows a t-distribution with <code>length(d) - 1</code> degrees of freedom, assuming 
normality of the differences <code>d</code>. 
<!--End alternate nroff text-->
<p>
(c) Pooled-Variance Two-Sample t-Test. 
<p>
If <code>y</code> is not <code>NULL</code> and <code>paired=FALSE</code>, either a pooled-variance 
or Welch modified 
two-sample t-test is performed, depending on whether <code>var.equal</code> is 
<code>TRUE</code> or <code>FALSE</code>. For the pooled-variance t-test, <code>statistic</code> is 
<!-- <special target="troff">
.Tr
<p>
t ~=~ { x bar ^-^ y  bar ~-~ roman "mu" } over {s sub 1} 
<p>
with
<p>
{s sub 1} ~=~ {s sub p} * sqrt { {1 over {n sub x}} ^+^ {1 over {n sub y}}}, 
<p>
{s sub p} ~=~ sqrt {{({n sub x}-1)^{s sub x sup 2} ~+~ ({n sub y}-1)^{s sub y sup 2}} over {{n sub x} ^+^ {n sub y} ^-^ 2}}. 
<p>
Here $x bar$, $y bar$, $s sub x sup 2$, $s sub y sup 2$, $n sub x$ and $n sub y$
are the sample means, sample variances and sample sizes of `x' and `y'.
Assuming that `x' and `y' come from normal populations
with equal variances, $t$  has a t-distribution
with ${n sub x} ^+^ {n sub y} ^-^ 2$ degrees of freedom under the null
hypothesis.
.En
</special> 
 -->
<!--Alternate nroff text-->
<br>
<code>t = (mean(x) - mean(y) - mu) / s1,</code> 
<br>
with 
<verb>
s1 = sp * sqrt(1/nx + 1/ny), 
sp = sqrt( ( (nx-1)*var(x) + (ny-1)*var(y) ) / (nx + ny - 2) ), 
nx = length(x),  ny = length(y). 
</verb>
Assuming that <code>x</code> and <code>y</code> come from normal populations 
with equal variances, <code>t</code>  has a t-distribution 
with <code>nx + ny - 2</code> degrees of freedom under the null 
hypothesis. 
<!--End alternate nroff text-->
<p>
(d) Welch Modified Two-Sample t-Test. 
<p>
If <code>y</code> is not <code>NULL</code>, <code>paired=FALSE</code> and <code>var.equal=FALSE</code>, the Welch 
modified two-sample t-test is performed. In this case <code>statistic</code> is 
<!-- <special target="troff">
.Tr
<p>
t ~=~ { x bar ^-^ y  bar ~-~ roman "mu" } over {s sub 2} 
<p>
with
<p>
{s sub 2} ~=~ sqrt { {{s sub x sup 2} over {n sub x}} ^+^ {{s sub y sup 2} over {n sub y}}  }. 
<p>
As before, $x bar$, $y bar$, $s sub x sup 2$, $s sub y sup 2$, $n sub x$ and $n sub y$
are the sample means, sample variances and sample sizes of `x' and `y'.
If `x' and `y' come from normal populations, the distribution of $t$
under the null hypothesis can be approximated
by a t-distribution with (non-integral) degrees of freedom
<p>
left [ { {{c sup 2} over {{n sub x} - 1}} ~+~ {{{(1 - c)} sup 2} over {{n sub y} - 1}}  } ~ right ] sup {-1} 
<p>
where
<p>
c ~=~ {s sub x sup 2} over { {n sub x} {{s sub 2} sup 2}  }. 
.En
</special> 
 -->
<!--Alternate nroff text-->
<br>
<code>t = (mean(x) - mean(y) - mu) / s2</code> 
<br>
with 
<verb>
s2 = sqrt( var(x)/nx + var(y)/ny ), 
nx = length(x),  ny = length(y). 
</verb>
If <code>x</code> and <code>y</code> come from normal populations, the distribution of <code>t</code> 
under the null hypothesis can be approximated 
by a t-distribution with (non-integral) degrees of freedom 
<br>
<code>1 / ( (c^2)/(nx-1) + ((1-c)^2)/(ny-1) )</code> 
<br>
where 
<br>
<code>c  = var(x) / (nx * s2^2).</code> 
<br>
<!--End alternate nroff text-->
</s-details>
<s-section name="CONFIDENCE INTERVALS">

For each of the above tests, an expression for the related confidence 
interval (returned component <code>conf.int</code>) can be obtained in the usual way 
by inverting the expression for the test statistic. Note however that, as 
explained under the description of <code>conf.int</code>, the confidence interval 
will be half-infinite when <code>alternative</code> is not <code>"two.sided"</code>; 
infinity will be represented by <code>NA</code>. 
</s-section>

<s-section name="REFERENCES">
Box, G. E. P. (1953), 
"Non-normality and Tests on Variances," 
<it>Biometrika,</it>
pp. 318-335. 
<p>
Hogg, R. V. and Craig, A. T. (1970), 
<it>Introduction to Mathematical Statistics,</it>
3rd ed.  Toronto, Canada: Macmillan. 
<p>
Mood, A. M., Graybill, F. A. and Boes, D. C. (1974), 
<it>Introduction to the Theory of Statistics,</it>
3rd ed.  New York: McGraw-Hill. 
<p>
Snedecor, G. W. and Cochran, W. G. (1980), 
<it>Statistical Methods,</it>
7th ed.  Ames, Iowa: Iowa State University Press. 
</s-section>

<s-see>
<s-function name="aov.sgm">aov</s-function>,  
<s-function name="wilcox.test.sgm">wilcox.test</s-function>.
</s-see>

<s-examples>
<s-example type = text>
x <- rnorm(12) 
t.test(x) 
        # Two-sided one-sample t-test. The null hypothesis is 
        # that the population mean for 'x' is zero. The 
        # alternative hypothesis states that it is either greater 
        # or less than zero. A confidence interval for the 
        # population mean will be computed. 
 
data.before <- c(31, 20, 18, 17, 9, 8, 10, 7) 
data.after <- c(18, 17, 14, 11, 10, 7, 5, 6) 
t.test(data.after, data.before, 
       alternative="less", paired=T) 
        # One-sided paired t-test. The null hypothesis is that 
        # the population mean "before" and the one "after" are 
        # the same, or equivalently that the mean change ("after" 
        # minus "before") is zero. The alternative hypothesis is 
        # that the mean "after" is less than the one "before", 
        # or equivalently that the mean change is negative. A 
        # confidence interval for the mean change will be 
        # computed. 
 
x <- c(7.8, 6.6, 6.5, 7.4, 7.3, 7., 6.4, 7.1, 6.7, 7.6, 6.8) 
y <- c(4.5, 5.4, 6.1, 6.1, 5.4, 5., 4.1, 5.5) 
t.test(x, y, mu=2) 
        # Two-sided pooled-variance two-sample t-test. 
        # This assumes that the two populations variances are equal. 
        # The null hypothesis is that the population mean for 'x'  
        # minus that for 'y' is 2. 
        # The alternative hypothesis is that this difference 
        # is not 2. A confidence interval for the true difference 
        # will be computed. 
 
t.test(x, y, var.equal=F, conf.level=0.90) 
        # Two-sided Welch modified two-sample t-test. The null 
        # hypothesis is that the population means for 'x' and 'y' 
        # are the same. The alternative hypothesis is that they 
        # are not. The confidence interval for the difference in 
        # true means ('x' minus 'y') will have a confidence level 
        # of 0.90. 
</s-example>
</s-examples>
<s-keywords>
<s-keyword>htest</s-keyword>
<s-keyword>resample</s-keyword>
<s-keyword>tilting</s-keyword>
</s-keywords>
<s-docclass>
function
</s-docclass>
</s-function-doc>
